{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Prediction from RGB and Infrared Input\n",
    "\n",
    "This model predicts a depth image given a rgb and an infrared input image of the same resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import Sequence # for data generator class\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Dropout, concatenate, Conv2DTranspose\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data situation\n",
    "Training data (as well as test data) will lie in directories with the following structure:\n",
    "\n",
    "<pre>\n",
    "data\n",
    "|-- train\n",
    "    |-- Color\n",
    "        |-- 1.jpg\n",
    "        |-- 2.jpg\n",
    "        ...\n",
    "        |-- n.jpg\n",
    "    |-- Infrared\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "    |-- Depth\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "|-- test\n",
    "    |-- Color\n",
    "    |-- Infrared\n",
    "    |-- Depth\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Generator\n",
    "Because there are many training and test images, it is reasonable to utilize a data loader, which reads training data batch wise. Because the default keras data loader (`ImageDataGenerator`) does not work with two input parameters, we need to write our own. For this, the tutorial from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly is utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Assumes that examples in the provided folder are named from 1 to n, with n being the number of images'\n",
    "    def __init__(self, path_to_data_set='data/train', batch_size=32, image_size=(480,640), shuffle=True):\n",
    "        self.path_to_data = path_to_data_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.training_size = self.__get_training_data_size(self.path_to_data)\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __get_training_data_size(self, path_to_data):\n",
    "        'gets the number of samples'\n",
    "        path_color = os.path.join(path_to_data,'Color')\n",
    "        if os.path.isdir(path_color):\n",
    "            size = len([color for color in os.listdir(path_color) if os.path.isfile(os.path.join(path_color, color))])\n",
    "            return size\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Number of batches per epoche'\n",
    "        return int(np.floor(self.training_size / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices (and their ordering) after each epoch'\n",
    "        # image names start with 1, np.arange(n,m) returns values from n to (m-1)\n",
    "        self.indices = np.arange(1, self.training_size+1)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __data_generation(self, list_images):\n",
    "        'Generates data of size batch_size' # X = (batch_size, 480, 640, 1)\n",
    "        X1 = np.empty((self.batch_size, *self.image_size, 3), dtype=np.uint8) # color images\n",
    "        X2 = np.empty((self.batch_size, *self.image_size), dtype=np.uint16) # ir image\n",
    "        y = np.empty((self.batch_size, *self.image_size), dtype=np.uint16)  # depth image\n",
    "        \n",
    "        # Generate data\n",
    "        for idx, name in enumerate(list_images):\n",
    "            # load images in arrays\n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Color', str(name)+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            X1[idx,] = img.astype(np.uint8)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Infrared', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            X2[idx,] = img.astype(np.uint16)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Depth', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            y[idx,] = img.astype(np.uint16)\n",
    "        \n",
    "        return X1, X2, y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data, X1 contains 8-bit RGB images, X2 16-bit infrared images and y corresponding 16-bit depth images'\n",
    "        # Generate indices of data\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Generate data\n",
    "        X1, X2, y = self.__data_generation(indices)\n",
    "        \n",
    "        return [X1, X2], y\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(\n",
    "    path_to_data_set='data/train',\n",
    "    batch_size=64,\n",
    "    image_size=(480,640),\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "validation_generator = DataGenerator(\n",
    "    path_to_data_set='data/validation',\n",
    "    batch_size=64,\n",
    "    image_size=(480.640),\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual model\n",
    "This section defines the network architecture of the neural network. It consists of different parts:\n",
    "- input layers\n",
    "- fusion layer\n",
    "- VGG16-like encoder network (configuration D) (see https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- mirrored decoder network\n",
    "- output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color branch\n",
    "input_color = Input(shape=(480,640,3), name=\"Color_Input\")\n",
    "x = Model(inputs=input_color, outputs=input_color)\n",
    "\n",
    "# Infrared branch\n",
    "input_ir = Input(shape=(480,640,1), name=\"Infrared_Input\")\n",
    "y = Model(inputs=input_ir, outputs=input_ir)\n",
    "\n",
    "# combine both branches\n",
    "combined = concatenate([x.output, y.output], name=\"Concatenate\")\n",
    "\n",
    "# VGG16 style encoder (configuration D)\n",
    "z = Conv2D(64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-64_1\")(combined)\n",
    "z = Conv2D(64, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-64\")(z)\n",
    "\n",
    "z = Conv2D(128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-128_1\")(z)\n",
    "z = Conv2D(128, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-128\")(z)\n",
    "\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_1\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_2\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-256_3\")(z)\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_1\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_2\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-512_3\")(z)\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_4\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_5\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-512_6\")(z)\n",
    "\n",
    "# end of encoder part\n",
    "# start of decoder part\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_7\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_8\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_1\")(z)\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_9\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_10\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_2\")(z)\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_11\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_12\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_3\")(z)\n",
    "\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_4\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_5\")(z)\n",
    "z = Conv2DTranspose(256, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-256\")(z)\n",
    "\n",
    "z = Conv2D(128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-128_2\")(z)\n",
    "z = Conv2DTranspose(128, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-128\")(z)\n",
    "\n",
    "z = Conv2D(64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-64_2\")(z)\n",
    "\n",
    "# end of decoder part\n",
    "# output layer\n",
    "z = Conv2D(1, kernel_size=(3,3), padding=\"same\", name=\"Conv3-1\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\",\n",
    "    metrics=['mae', 'mse'])\n",
    "\n",
    "\n",
    "\n",
    "# TODO: MaxPool and UpPool replaced with __extra__ conv layer? or simply add strides to last conv layer?\n",
    "# TODO: add BatchNormalization layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Color_Input (InputLayer)        (None, 480, 640, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Infrared_Input (InputLayer)     (None, 480, 640, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Concatenate (Concatenate)       (None, 480, 640, 4)  0           Color_Input[0][0]                \n",
      "                                                                 Infrared_Input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_1 (Conv2D)             (None, 480, 640, 64) 2368        Concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64 (Conv2D)               (None, 240, 320, 64) 36928       Conv3-64_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_1 (Conv2D)            (None, 240, 320, 128 73856       Conv3-64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128 (Conv2D)              (None, 120, 160, 128 147584      Conv3-128_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_1 (Conv2D)            (None, 120, 160, 256 295168      Conv3-128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_2 (Conv2D)            (None, 120, 160, 256 590080      Conv3-256_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_3 (Conv2D)            (None, 60, 80, 256)  590080      Conv3-256_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_1 (Conv2D)            (None, 60, 80, 512)  1180160     Conv3-256_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_2 (Conv2D)            (None, 60, 80, 512)  2359808     Conv3-512_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_3 (Conv2D)            (None, 30, 40, 512)  2359808     Conv3-512_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_4 (Conv2D)            (None, 30, 40, 512)  2359808     Conv3-512_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_5 (Conv2D)            (None, 30, 40, 512)  2359808     Conv3-512_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_6 (Conv2D)            (None, 15, 20, 512)  2359808     Conv3-512_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_7 (Conv2D)            (None, 15, 20, 512)  2359808     Conv3-512_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_8 (Conv2D)            (None, 15, 20, 512)  2359808     Conv3-512_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DeConv3-512_1 (Conv2DTranspose) (None, 30, 40, 512)  2359808     Conv3-512_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_9 (Conv2D)            (None, 30, 40, 512)  2359808     DeConv3-512_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_10 (Conv2D)           (None, 30, 40, 512)  2359808     Conv3-512_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DeConv3-512_2 (Conv2DTranspose) (None, 60, 80, 512)  2359808     Conv3-512_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_11 (Conv2D)           (None, 60, 80, 512)  2359808     DeConv3-512_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_12 (Conv2D)           (None, 60, 80, 512)  2359808     Conv3-512_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "DeConv3-512_3 (Conv2DTranspose) (None, 120, 160, 512 2359808     Conv3-512_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_4 (Conv2D)            (None, 120, 160, 256 1179904     DeConv3-512_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_5 (Conv2D)            (None, 120, 160, 256 590080      Conv3-256_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DeConv3-256 (Conv2DTranspose)   (None, 240, 320, 256 590080      Conv3-256_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_2 (Conv2D)            (None, 240, 320, 128 295040      DeConv3-256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DeConv3-128 (Conv2DTranspose)   (None, 480, 640, 128 147584      Conv3-128_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_2 (Conv2D)             (None, 480, 640, 64) 73792       DeConv3-128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-1 (Conv2D)                (None, 480, 640, 1)  577         Conv3-64_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 38,830,593\n",
      "Trainable params: 38,830,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=os.path.join('Images','model.png'), show_shapes=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    generator=training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
