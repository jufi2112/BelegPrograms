{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Prediction from RGB and Infrared Input\n",
    "\n",
    "This model predicts a depth image given a rgb and an infrared input image of the same resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import Sequence # for data generator class\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Dropout, concatenate, Conv2DTranspose\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data situation\n",
    "Training data (as well as test data) will lie in directories with the following structure:\n",
    "\n",
    "<pre>\n",
    "data\n",
    "|-- train\n",
    "    |-- Color\n",
    "        |-- 1.jpg\n",
    "        |-- 2.jpg\n",
    "        ...\n",
    "        |-- n.jpg\n",
    "    |-- Infrared\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "    |-- Depth\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "|-- test\n",
    "    |-- Color\n",
    "    |-- Infrared\n",
    "    |-- Depth\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Generator\n",
    "Because there are many training and test images, it is reasonable to utilize a data loader, which reads training data batch wise. Because the default keras data loader (`ImageDataGenerator`) does not work with two input parameters, we need to write our own. For this, the tutorial from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly is utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Assumes that examples in the provided folder are named from 1 to n, with n being the number of images'\n",
    "    def __init__(self, path_to_data_set='data/train', batch_size=32, image_size=(480,640), shuffle=True):\n",
    "        self.path_to_data = path_to_data_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.training_size = self.__get_training_data_size(self.path_to_data)\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __get_training_data_size(self, path_to_data):\n",
    "        'gets the number of samples'\n",
    "        path_color = os.path.join(path_to_data,'Color')\n",
    "        if os.path.isdir(path_color):\n",
    "            size = len([color for color in os.listdir(path_color) if os.path.isfile(os.path.join(path_color, color))])\n",
    "            return size\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Number of batches per epoche'\n",
    "        return int(np.floor(self.training_size / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices (and their ordering) after each epoch'\n",
    "        # image names start with 1, np.arange(n,m) returns values from n to (m-1)\n",
    "        self.indices = np.arange(1, self.training_size+1)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __data_generation(self, list_images):\n",
    "        'Generates data of size batch_size' # X = (batch_size, 480, 640, 1)\n",
    "        X1 = np.empty((self.batch_size, *self.image_size, 3), dtype=np.uint8) # color images\n",
    "        X2 = np.empty((self.batch_size, *self.image_size), dtype=np.uint16) # ir image\n",
    "        y = np.empty((self.batch_size, *self.image_size), dtype=np.uint16)  # depth image\n",
    "        \n",
    "        # Generate data\n",
    "        for idx, name in enumerate(list_images):\n",
    "            # load images in arrays\n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Color', str(name)+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            X1[idx,] = img.astype(np.uint8)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Infrared', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            X2[idx,] = img.astype(np.uint16)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Depth', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            y[idx,] = img.astype(np.uint16)\n",
    "        \n",
    "        return X1, X2, y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data, X1 contains 8-bit RGB images, X2 16-bit infrared images and y corresponding 16-bit depth images'\n",
    "        # Generate indices of data\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Generate data\n",
    "        X1, X2, y = self.__data_generation(indices)\n",
    "        \n",
    "        return [X1, X2], y\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(\n",
    "    path_to_data_set='data/train',\n",
    "    batch_size=64,\n",
    "    image_size=(480,640),\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "validation_generator = DataGenerator(\n",
    "    path_to_data_set='data/validation',\n",
    "    batch_size=64,\n",
    "    image_size=(480.640),\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual model\n",
    "This section defines the network architecture of the neural network. It consists of different parts:\n",
    "- input layers\n",
    "- fusion layer\n",
    "- VGG16-like encoder network (configuration D) (see https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- mirrored decoder network\n",
    "- output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color branch\n",
    "input_color = Input(shape=(480,640,3), name=\"Color_Input\")\n",
    "x = Model(inputs=input_color, outputs=input_color)\n",
    "\n",
    "# Infrared branch\n",
    "input_ir = Input(shape=(480,640,1), name=\"Infrared_Input\")\n",
    "y = Model(inputs=input_ir, outputs=input_ir)\n",
    "\n",
    "# combine both branches\n",
    "combined = concatenate([x.output, y.output], name=\"Concatenate\")\n",
    "\n",
    "# VGG16 style encoder (configuration D)\n",
    "z = Conv2D(64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-64_1\")(combined)\n",
    "z = Conv2D(64, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-64\")(z)\n",
    "\n",
    "z = Conv2D(128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-128_1\")(z)\n",
    "z = Conv2D(128, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-128\")(z)\n",
    "\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_1\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_2\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-256_3\")(z)\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_1\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_2\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-512_3\")(z)\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_4\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_5\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-512_6\")(z)\n",
    "\n",
    "# end of encoder part\n",
    "# start of decoder part\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_7\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_8\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_1\")(z)\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_9\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_10\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_2\")(z)\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_11\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_12\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_3\")(z)\n",
    "\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_4\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_5\")(z)\n",
    "z = Conv2DTranspose(256, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-256\")(z)\n",
    "\n",
    "z = Conv2D(128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-128_2\")(z)\n",
    "z = Conv2DTranspose(128, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-128\")(z)\n",
    "\n",
    "z = Conv2D(64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-64_2\")(z)\n",
    "\n",
    "# end of decoder part\n",
    "# output layer\n",
    "z = Conv2D(1, kernel_size=(3,3), padding=\"same\", name=\"Conv3-1\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\",\n",
    "    metrics=['mae', 'mse'])\n",
    "\n",
    "\n",
    "\n",
    "# TODO: MaxPool and UpPool replaced with __extra__ conv layer? or simply add strides to last conv layer?\n",
    "# TODO: add BatchNormalization layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"dot\" with args ['-Tps', 'C:\\\\Users\\\\Julien\\\\AppData\\\\Local\\\\Temp\\\\tmp9cq04c9n'] returned code: 1\n",
      "\n",
      "stdout, stderr:\n",
      " b''\n",
      "b'Der Befehl \"D:\\\\Program\" ist entweder falsch geschrieben oder\\r\\nkonnte nicht gefunden werden.\\r\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c1d430ea67d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'D:/Users/Julien/Documents/Uni/BelegPrograms/Learning/Images/model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Attempt to create an image of a blank graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         raise OSError(\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1943\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1945\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1947\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstdout_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=os.path.join('Images','model.png'), show_shapes=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
