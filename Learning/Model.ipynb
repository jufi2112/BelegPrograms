{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Prediction from RGB and Infrared Input\n",
    "\n",
    "This model predicts a depth image given a rgb and an infrared input image of the same resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import Sequence # for data generator class\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Dropout, concatenate, Conv2DTranspose\n",
    "from keras.layers import Add # for skip connections\n",
    "from keras.utils import plot_model\n",
    "import json # for saving training history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data situation\n",
    "Training data (as well as test and validation data) will lie in directories with the following structure:\n",
    "\n",
    "<pre>\n",
    "data\n",
    "|-- train\n",
    "    |-- Color\n",
    "        |-- 1.jpg\n",
    "        |-- 2.jpg\n",
    "        ...\n",
    "        |-- n.jpg\n",
    "    |-- Infrared\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "    |-- Depth\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "|-- test\n",
    "    |-- Color\n",
    "    |-- Infrared\n",
    "    |-- Depth\n",
    "|-- validation\n",
    "    |-- Color\n",
    "    |-- Infrared\n",
    "    |-- Depth\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Generator\n",
    "Because there are many training and test images, it is reasonable to utilize a data loader, which reads training data batch wise. Because the default keras data loader (`ImageDataGenerator`) does not work with two input parameters, we need to write our own. For this, the tutorial from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly is utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Assumes that examples in the provided folder are named from 1 to n, with n being the number of images'\n",
    "    def __init__(self, path_to_data_set='data/train', batch_size=32, image_size=(480,640), shuffle=True, scale_images=False):\n",
    "        self.path_to_data = path_to_data_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.scale_images = scale_images\n",
    "        self.training_size = self.__get_training_data_size(self.path_to_data)\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __get_training_data_size(self, path_to_data):\n",
    "        'gets the number of samples'\n",
    "        path_color = os.path.join(path_to_data,'Color')\n",
    "        if os.path.isdir(path_color):\n",
    "            size = len([color for color in os.listdir(path_color) if os.path.isfile(os.path.join(path_color, color))])\n",
    "            return size\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Number of batches per epoche'\n",
    "        return int(np.floor(self.training_size / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices (and their ordering) after each epoch'\n",
    "        # image names start with 1, np.arange(n,m) returns values from n to (m-1)\n",
    "        self.indices = np.arange(1, self.training_size+1)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __data_generation(self, list_images):\n",
    "        'Generates data of size batch_size' # X = (batch_size, 480, 640, 1)\n",
    "        if self.scale_images == False:\n",
    "            X1 = np.empty((self.batch_size, *self.image_size, 3), dtype=np.uint8) # color images\n",
    "            X2 = np.empty((self.batch_size, *self.image_size), dtype=np.uint16) # ir image\n",
    "        else:\n",
    "            X1 = np.empty((self.batch_size, *self.image_size, 3), dtype=np.float32) # color images\n",
    "            X2 = np.empty((self.batch_size, *self.image_size), dtype=np.float32) # ir image\n",
    "        y = np.empty((self.batch_size, *self.image_size), dtype=np.uint16)  # depth image\n",
    "        \n",
    "        # Generate data\n",
    "        for idx, name in enumerate(list_images):\n",
    "            # load images in arrays\n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Color', str(name)+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            if self.scale_images == False:\n",
    "                X1[idx,] = img.astype(np.uint8)\n",
    "            else:\n",
    "                X1[idx,] = (img/255.).astype(np.float32)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Infrared', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            if self.scale_images == False:\n",
    "                X2[idx,] = img.astype(np.uint16)\n",
    "            else:\n",
    "                X2[idx,] = (img/65535.).astype(np.float32)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Depth', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            y[idx,] = img.astype(np.uint16)\n",
    "        \n",
    "        return X1, X2.reshape(-1, 480, 640, 1), y.reshape(-1, 480, 640, 1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data, X1 contains 8-bit RGB images, X2 16-bit infrared images and y corresponding 16-bit depth images'\n",
    "        # Generate indices of data\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Generate data\n",
    "        X1, X2, y = self.__data_generation(indices)\n",
    "        \n",
    "        return [X1, X2], y\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(\n",
    "    path_to_data_set=os.path.join('data', 'train'),\n",
    "    batch_size=32,\n",
    "    image_size=(480,640),\n",
    "    shuffle=True,\n",
    "    scale_images=True\n",
    "    )\n",
    "\n",
    "validation_generator = DataGenerator(\n",
    "    path_to_data_set=os.path.join('data', 'validation'),\n",
    "    batch_size=32,\n",
    "    image_size=(480,640),\n",
    "    shuffle=True,\n",
    "    scale_images=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Class Definition\n",
    "To make the model more friendly to read (and to prevent the repetition of layer code), this part defines functions to create multiple layers at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG:\n",
    "    'Class that contains building blocks for a residual VGG-like autoencoder network'\n",
    "    def __init__(self):\n",
    "        self.layer_counting = {}\n",
    "        \n",
    "    def Block(self, number_of_layers, units, kernel_size, padding, activation):\n",
    "        'A block of <number_of_layers> convolutions with batch normalization added AFTER the non-linearity'\n",
    "        def Input(z):\n",
    "            for i in range(1,number_of_layers+1):\n",
    "                name = 'Conv' + str(kernel_size[0]) + '-' + str(units)\n",
    "                # make sure we have unique layer names\n",
    "                if name in self.layer_counting:\n",
    "                    self.layer_counting[name] += 1\n",
    "                else:\n",
    "                    self.layer_counting[name] = 1\n",
    "                name += '_' + str(self.layer_counting[name])\n",
    "                name_bn = name + '_BN'\n",
    "                z = Conv2D(filters=units, kernel_size=kernel_size, padding=padding, activation=activation, name=name)(z)\n",
    "                z = BatchNormalization(name=name_bn)(z)\n",
    "            return z\n",
    "        return Input\n",
    "    \n",
    "    def Residual_Downsampling_Block(self, units, kernel_size, padding, activation):\n",
    "        'A block with a strided convolution for downsampling an the start of a skip connection'\n",
    "        def Input(z):\n",
    "            skip = z\n",
    "            name = 'DownConv' + str(kernel_size[0]) + '-' + str(units)\n",
    "            # make sure we have unique layer names\n",
    "            if name in self.layer_counting:\n",
    "                self.layer_counting[name] += 1\n",
    "            else:\n",
    "                self.layer_counting[name] = 1\n",
    "            name += '_' + str(self.layer_counting[name])\n",
    "            name_bn = name + '_BN'\n",
    "            z = Conv2D(filters=units, kernel_size=kernel_size, strides=(2,2), padding=padding, activation=activation, name=name)(z)\n",
    "            z = BatchNormalization(name=name_bn)(z)\n",
    "            return z, skip\n",
    "        return Input\n",
    "    \n",
    "    def Residual_Upsampling_Block(self, units, kernel_size, padding, activation):\n",
    "        'A block with a transposed convolution (also called deconvolution) and the incorporation of a provided skip connection'\n",
    "        def Input(z, skip):\n",
    "            name = 'UpConv' + str(kernel_size[0]) + '-' + str(units)\n",
    "            # make sure we have unique layer names\n",
    "            if name in self.layer_counting:\n",
    "                self.layer_counting[name] += 1\n",
    "            else:\n",
    "                self.layer_counting[name] = 1\n",
    "            name += '_' + str(self.layer_counting[name])\n",
    "            name_add = name + '_skip'\n",
    "            name_bn = name + '_BN'\n",
    "            z = Conv2DTranspose(filters=units, kernel_size=kernel_size, strides=(2,2), padding=\"same\", name=name)(z)\n",
    "            z = Add(name=name_add)([z, skip])\n",
    "            z = Activation(activation)(z)\n",
    "            z = BatchNormalization(name=name_bn)(z)\n",
    "            return z\n",
    "        return Input\n",
    "    \n",
    "    def Residual_Block(self, number_of_layers, units, kernel_size, padding, activation):\n",
    "        'A block of <number_of_layers> covolutions with provided skip connection incorporated after the last convolutional layer'\n",
    "        def Input(z, skip):\n",
    "            for i in range(1, number_of_layers+1):\n",
    "                name = 'Conv2D' + str(kernel_size[0]) + '-' + str(units)\n",
    "                # make sure we have unique layer names\n",
    "                if name in self.layer_counting:\n",
    "                    self.layer_counting[name] += 1\n",
    "                else:\n",
    "                    self.layer_counting[name] = 1\n",
    "                name += '_' + str(self.layer_counting[name])\n",
    "                name_add = name + '_skip'\n",
    "                name_bn = name + '_BN'\n",
    "                z = Conv2D(filters=units, kernel_size=kernel_size, padding=padding)(z)\n",
    "                if i == number_of_layers:\n",
    "                    z = Add(name=name_add)([z, skip])\n",
    "                z = Activation(activation)(z)\n",
    "                z = BatchNormalization(name=name_bn)(z)\n",
    "            return z\n",
    "        return Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function\n",
    "Here a custom loss function is implemented. It is based on the mean absolut error but uses a binary map to eliminate the influence of artifacts in the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Binary_Mean_Absolut_Error():\n",
    "    def bmae(y_true, y_pred):\n",
    "        # shape of y_true and y_pred is (batch_size, 480, 640, 1); rank = 4\n",
    "        # edit by fabian\n",
    "        y_zero = tf.zeros(tf.shape(y_true))  # rank = 4\n",
    "        A_i = tf.math.greater(y_true, y_zero) # rank = 4\n",
    "        A_i_sum = tf.reduce_sum(A_i, axis = (1, rank(A_i))) # sum for every batch; rank = 1, but still a 1D vector  \n",
    "        \n",
    "        A_comb = tf.math.multiply(A_i, tf.math.abs(tf.math.subtract(y_true, y_pred))) # A * |y_true - y_pred|; rank = 4\n",
    "        A_batch = tf.reduce_sum(A_comb, axis = (1, rank(A_comb))) # should be rank = 1\n",
    "        \n",
    "        A_divide = tf.math.divide(A_batch, A_i_sum) # still rank = 1\n",
    "        \n",
    "        output = tf.reduce_sum(A_divide) # rank = 0 --> a scalar = Loss for the whole batch\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual model\n",
    "This section defines the network architecture of the neural network. It consists of different parts:\n",
    "- input layers\n",
    "- fusion layer\n",
    "- VGG16-like encoder network (configuration D) (see https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- mirrored decoder network\n",
    "- output\n",
    "\n",
    "The encoder and decoder sections are connected through skip connections between layers of equal spatial size (as described in https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG()\n",
    "# Color branch\n",
    "input_color = Input(shape=(480,640,3), name=\"Color_Input\")\n",
    "x = Model(inputs=input_color, outputs=input_color)\n",
    "\n",
    "# Infrared branch\n",
    "input_ir = Input(shape=(480,640,1), name=\"Infrared_Input\")\n",
    "y = Model(inputs=input_ir, outputs=input_ir)\n",
    "\n",
    "# combine both branches\n",
    "combined = concatenate([x.output, y.output], name=\"Concatenate\")\n",
    "\n",
    "# zeroth skip connection start --> to transfer original input images to the end of the network\n",
    "skip_zero = combined\n",
    "\n",
    "# VGG16 style encoder (configuration D)\n",
    "\n",
    "z = vgg.Block(number_of_layers=2, units=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(combined)\n",
    "# max pooling replaced with strided convolution + first skip connection start\n",
    "z, skip_one = vgg.Residual_Downsampling_Block(units=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "z = vgg.Block(number_of_layers=2, units=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "# max pooling replaced with strided convolution + second skip connection start\n",
    "z, skip_two = vgg.Residual_Downsampling_Block(units=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "z = vgg.Block(number_of_layers=3, units=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "# max pooling replaced with strided convolution + third skip connection start\n",
    "z, skip_three = vgg.Residual_Downsampling_Block(units=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "# max pooling replaced with strided convolution + fourth skip connection start\n",
    "z, skip_four = vgg.Residual_Downsampling_Block(units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "# max pooling replaced with strided convolution + fifth skip connection start\n",
    "z, skip_five = vgg.Residual_Downsampling_Block(units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "# end of encoder part\n",
    "\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "# start of decoder part (= mirrored encoder part)\n",
    "\n",
    "# upsampling with deconvolution + fifth skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_five)\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "# upsampling with deconvolution + fourth skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_four)\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "# upsampling with deconvolution + third skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_three)\n",
    "z = vgg.Block(number_of_layers=3, units=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "# upsampling with deconvolution + second skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_two)\n",
    "z = vgg.Block(number_of_layers=2, units=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "# upsampling with deconvolution + first skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_one)\n",
    "z = vgg.Block(number_of_layers=2, units=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "# end of decoder part\n",
    "\n",
    "# TODO does incorporating skip_zero in this way makes sense?\n",
    "z = vgg.Residual_Block(number_of_layers=1, units=4, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_zero)\n",
    "\n",
    "# output layer\n",
    "z = Conv2D(1, kernel_size=(3,3), padding=\"same\", name=\"Conv_Output\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\",\n",
    "    metrics=['mae', 'mse'])\n",
    "\n",
    "# TODO implement own loss function: https://towardsdatascience.com/advanced-keras-constructing-complex-custom-losses-and-metrics-c07ca130a618\n",
    "# and https://medium.com/@yanfengliux/on-writing-custom-loss-functions-in-keras-e04290dd7a96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Color_Input (InputLayer)        (None, 480, 640, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Infrared_Input (InputLayer)     (None, 480, 640, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Concatenate (Concatenate)       (None, 480, 640, 4)  0           Color_Input[0][0]                \n",
      "                                                                 Infrared_Input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_1 (Conv2D)             (None, 480, 640, 64) 2368        Concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_1_BN (BatchNormalizati (None, 480, 640, 64) 256         Conv3-64_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_2 (Conv2D)             (None, 480, 640, 64) 36928       Conv3-64_1_BN[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_2_BN (BatchNormalizati (None, 480, 640, 64) 256         Conv3-64_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-64_1 (Conv2D)         (None, 240, 320, 64) 36928       Conv3-64_2_BN[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-64_1_BN (BatchNormali (None, 240, 320, 64) 256         DownConv3-64_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_1 (Conv2D)            (None, 240, 320, 128 73856       DownConv3-64_1_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_1_BN (BatchNormalizat (None, 240, 320, 128 512         Conv3-128_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_2 (Conv2D)            (None, 240, 320, 128 147584      Conv3-128_1_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_2_BN (BatchNormalizat (None, 240, 320, 128 512         Conv3-128_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-128_1 (Conv2D)        (None, 120, 160, 128 147584      Conv3-128_2_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-128_1_BN (BatchNormal (None, 120, 160, 128 512         DownConv3-128_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_1 (Conv2D)            (None, 120, 160, 256 295168      DownConv3-128_1_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_1_BN (BatchNormalizat (None, 120, 160, 256 1024        Conv3-256_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_2 (Conv2D)            (None, 120, 160, 256 590080      Conv3-256_1_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_2_BN (BatchNormalizat (None, 120, 160, 256 1024        Conv3-256_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_3 (Conv2D)            (None, 120, 160, 256 590080      Conv3-256_2_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_3_BN (BatchNormalizat (None, 120, 160, 256 1024        Conv3-256_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-256_1 (Conv2D)        (None, 60, 80, 256)  590080      Conv3-256_3_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-256_1_BN (BatchNormal (None, 60, 80, 256)  1024        DownConv3-256_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_1 (Conv2D)            (None, 60, 80, 512)  1180160     DownConv3-256_1_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_1_BN (BatchNormalizat (None, 60, 80, 512)  2048        Conv3-512_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_2 (Conv2D)            (None, 60, 80, 512)  2359808     Conv3-512_1_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_2_BN (BatchNormalizat (None, 60, 80, 512)  2048        Conv3-512_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_3 (Conv2D)            (None, 60, 80, 512)  2359808     Conv3-512_2_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_3_BN (BatchNormalizat (None, 60, 80, 512)  2048        Conv3-512_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-512_1 (Conv2D)        (None, 30, 40, 512)  2359808     Conv3-512_3_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-512_1_BN (BatchNormal (None, 30, 40, 512)  2048        DownConv3-512_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_4 (Conv2D)            (None, 30, 40, 512)  2359808     DownConv3-512_1_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_4_BN (BatchNormalizat (None, 30, 40, 512)  2048        Conv3-512_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_5 (Conv2D)            (None, 30, 40, 512)  2359808     Conv3-512_4_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_5_BN (BatchNormalizat (None, 30, 40, 512)  2048        Conv3-512_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_6 (Conv2D)            (None, 30, 40, 512)  2359808     Conv3-512_5_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_6_BN (BatchNormalizat (None, 30, 40, 512)  2048        Conv3-512_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-512_2 (Conv2D)        (None, 15, 20, 512)  2359808     Conv3-512_6_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DownConv3-512_2_BN (BatchNormal (None, 15, 20, 512)  2048        DownConv3-512_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_7 (Conv2D)            (None, 15, 20, 512)  2359808     DownConv3-512_2_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_7_BN (BatchNormalizat (None, 15, 20, 512)  2048        Conv3-512_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_8 (Conv2D)            (None, 15, 20, 512)  2359808     Conv3-512_7_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_8_BN (BatchNormalizat (None, 15, 20, 512)  2048        Conv3-512_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_9 (Conv2D)            (None, 15, 20, 512)  2359808     Conv3-512_8_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_9_BN (BatchNormalizat (None, 15, 20, 512)  2048        Conv3-512_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-512_1 (Conv2DTranspose) (None, 30, 40, 512)  2359808     Conv3-512_9_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-512_1_skip (Add)        (None, 30, 40, 512)  0           UpConv3-512_1[0][0]              \n",
      "                                                                 Conv3-512_6_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 30, 40, 512)  0           UpConv3-512_1_skip[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-512_1_BN (BatchNormaliz (None, 30, 40, 512)  2048        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_10 (Conv2D)           (None, 30, 40, 512)  2359808     UpConv3-512_1_BN[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_10_BN (BatchNormaliza (None, 30, 40, 512)  2048        Conv3-512_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_11 (Conv2D)           (None, 30, 40, 512)  2359808     Conv3-512_10_BN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_11_BN (BatchNormaliza (None, 30, 40, 512)  2048        Conv3-512_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_12 (Conv2D)           (None, 30, 40, 512)  2359808     Conv3-512_11_BN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_12_BN (BatchNormaliza (None, 30, 40, 512)  2048        Conv3-512_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-512_2 (Conv2DTranspose) (None, 60, 80, 512)  2359808     Conv3-512_12_BN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-512_2_skip (Add)        (None, 60, 80, 512)  0           UpConv3-512_2[0][0]              \n",
      "                                                                 Conv3-512_3_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 60, 80, 512)  0           UpConv3-512_2_skip[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-512_2_BN (BatchNormaliz (None, 60, 80, 512)  2048        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_13 (Conv2D)           (None, 60, 80, 512)  2359808     UpConv3-512_2_BN[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_13_BN (BatchNormaliza (None, 60, 80, 512)  2048        Conv3-512_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_14 (Conv2D)           (None, 60, 80, 512)  2359808     Conv3-512_13_BN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_14_BN (BatchNormaliza (None, 60, 80, 512)  2048        Conv3-512_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_15 (Conv2D)           (None, 60, 80, 512)  2359808     Conv3-512_14_BN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-512_15_BN (BatchNormaliza (None, 60, 80, 512)  2048        Conv3-512_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-256_1 (Conv2DTranspose) (None, 120, 160, 256 1179904     Conv3-512_15_BN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-256_1_skip (Add)        (None, 120, 160, 256 0           UpConv3-256_1[0][0]              \n",
      "                                                                 Conv3-256_3_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 120, 160, 256 0           UpConv3-256_1_skip[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-256_1_BN (BatchNormaliz (None, 120, 160, 256 1024        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_4 (Conv2D)            (None, 120, 160, 256 590080      UpConv3-256_1_BN[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_4_BN (BatchNormalizat (None, 120, 160, 256 1024        Conv3-256_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_5 (Conv2D)            (None, 120, 160, 256 590080      Conv3-256_4_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_5_BN (BatchNormalizat (None, 120, 160, 256 1024        Conv3-256_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_6 (Conv2D)            (None, 120, 160, 256 590080      Conv3-256_5_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-256_6_BN (BatchNormalizat (None, 120, 160, 256 1024        Conv3-256_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-128_1 (Conv2DTranspose) (None, 240, 320, 128 295040      Conv3-256_6_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-128_1_skip (Add)        (None, 240, 320, 128 0           UpConv3-128_1[0][0]              \n",
      "                                                                 Conv3-128_2_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 240, 320, 128 0           UpConv3-128_1_skip[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-128_1_BN (BatchNormaliz (None, 240, 320, 128 512         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_3 (Conv2D)            (None, 240, 320, 128 147584      UpConv3-128_1_BN[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_3_BN (BatchNormalizat (None, 240, 320, 128 512         Conv3-128_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_4 (Conv2D)            (None, 240, 320, 128 147584      Conv3-128_3_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-128_4_BN (BatchNormalizat (None, 240, 320, 128 512         Conv3-128_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-64_1 (Conv2DTranspose)  (None, 480, 640, 64) 73792       Conv3-128_4_BN[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-64_1_skip (Add)         (None, 480, 640, 64) 0           UpConv3-64_1[0][0]               \n",
      "                                                                 Conv3-64_2_BN[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 480, 640, 64) 0           UpConv3-64_1_skip[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "UpConv3-64_1_BN (BatchNormaliza (None, 480, 640, 64) 256         activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_3 (Conv2D)             (None, 480, 640, 64) 36928       UpConv3-64_1_BN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_3_BN (BatchNormalizati (None, 480, 640, 64) 256         Conv3-64_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_4 (Conv2D)             (None, 480, 640, 64) 36928       Conv3-64_3_BN[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3-64_4_BN (BatchNormalizati (None, 480, 640, 64) 256         Conv3-64_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 480, 640, 4)  2308        Conv3-64_4_BN[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D3-4_1_skip (Add)          (None, 480, 640, 4)  0           conv2d_3[0][0]                   \n",
      "                                                                 Concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 480, 640, 4)  0           Conv2D3-4_1_skip[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D3-4_1_BN (BatchNormalizat (None, 480, 640, 4)  16          activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv_Output (Conv2D)            (None, 480, 640, 1)  37          Conv2D3-4_1_BN[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 49,909,433\n",
      "Trainable params: 49,883,569\n",
      "Non-trainable params: 25,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#plot_model(model, to_file=os.path.join('Images','model.png'), show_shapes=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "           generator=training_generator,\n",
    "           validation_data=validation_generator,\n",
    "           #use_multiprocessing=True,\n",
    "           #workers=6,\n",
    "           epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.json', 'w') as f:\n",
    "    json.dump(hist.history, f)\n",
    "    \n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
