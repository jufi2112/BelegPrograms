{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Prediction from RGB and Infrared Input\n",
    "\n",
    "This model predicts a depth image given a rgb and an infrared input image of the same resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import Sequence # for data generator class\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Dropout, concatenate, Conv2DTranspose\n",
    "from keras.layers import Add # for skip connections\n",
    "from keras.utils import plot_model\n",
    "import json # for saving training history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data situation\n",
    "Training data (as well as test and validation data) will lie in directories with the following structure:\n",
    "\n",
    "<pre>\n",
    "data\n",
    "|-- train\n",
    "    |-- Color\n",
    "        |-- 1.jpg\n",
    "        |-- 2.jpg\n",
    "        ...\n",
    "        |-- n.jpg\n",
    "    |-- Infrared\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "    |-- Depth\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "|-- test\n",
    "    |-- Color\n",
    "    |-- Infrared\n",
    "    |-- Depth\n",
    "|-- validation\n",
    "    |-- Color\n",
    "    |-- Infrared\n",
    "    |-- Depth\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Generator\n",
    "Because there are many training and test images, it is reasonable to utilize a data loader, which reads training data batch wise. Because the default keras data loader (`ImageDataGenerator`) does not work with two input parameters, we need to write our own. For this, the tutorial from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly is utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Assumes that examples in the provided folder are named from 1 to n, with n being the number of images'\n",
    "    def __init__(self, path_to_data_set='data/train', batch_size=32, image_size=(480,640), shuffle=True):\n",
    "        self.path_to_data = path_to_data_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.training_size = self.__get_training_data_size(self.path_to_data)\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __get_training_data_size(self, path_to_data):\n",
    "        'gets the number of samples'\n",
    "        path_color = os.path.join(path_to_data,'Color')\n",
    "        if os.path.isdir(path_color):\n",
    "            size = len([color for color in os.listdir(path_color) if os.path.isfile(os.path.join(path_color, color))])\n",
    "            return size\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Number of batches per epoche'\n",
    "        return int(np.floor(self.training_size / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices (and their ordering) after each epoch'\n",
    "        # image names start with 1, np.arange(n,m) returns values from n to (m-1)\n",
    "        self.indices = np.arange(1, self.training_size+1)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __data_generation(self, list_images):\n",
    "        'Generates data of size batch_size' # X = (batch_size, 480, 640, 1)\n",
    "        X1 = np.empty((self.batch_size, *self.image_size, 3), dtype=np.uint8) # color images\n",
    "        X2 = np.empty((self.batch_size, *self.image_size), dtype=np.uint16) # ir image\n",
    "        y = np.empty((self.batch_size, *self.image_size), dtype=np.uint16)  # depth image\n",
    "        \n",
    "        # Generate data\n",
    "        for idx, name in enumerate(list_images):\n",
    "            # load images in arrays\n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Color', str(name)+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            X1[idx,] = img.astype(np.uint8)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Infrared', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            X2[idx,] = img.astype(np.uint16)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Depth', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            y[idx,] = img.astype(np.uint16)\n",
    "        \n",
    "        return X1, X2.reshape(-1, 480, 640, 1), y.reshape(-1, 480, 640, 1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data, X1 contains 8-bit RGB images, X2 16-bit infrared images and y corresponding 16-bit depth images'\n",
    "        # Generate indices of data\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Generate data\n",
    "        X1, X2, y = self.__data_generation(indices)\n",
    "        \n",
    "        return [X1, X2], y\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(\n",
    "    path_to_data_set=os.path.join('data', 'train'),\n",
    "    batch_size=32,\n",
    "    image_size=(480,640),\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "validation_generator = DataGenerator(\n",
    "    path_to_data_set=os.path.join('data', 'validation'),\n",
    "    batch_size=32,\n",
    "    image_size=(480,640),\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual model\n",
    "This section defines the network architecture of the neural network. It consists of different parts:\n",
    "- input layers\n",
    "- fusion layer\n",
    "- VGG16-like encoder network (configuration D) (see https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- mirrored decoder network\n",
    "- output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1019 00:56:04.761277 140214117746496 deprecation_wrapper.py:119] From /home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1019 00:56:05.044044 140214117746496 deprecation_wrapper.py:119] From /home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1019 00:56:05.086733 140214117746496 deprecation_wrapper.py:119] From /home/julien/anaconda3/envs/mlenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (60, 80, 512) (60, 80, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9e41e25bdb4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# fourth skip connection end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_four\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Conv3-512_11\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             output_shape = self._compute_elemwise_op_output_shape(output_shape,\n\u001b[0;32m---> 91\u001b[0;31m                                                                   shape)\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# to make them broadcastable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     raise ValueError('Operands could not be broadcast '\n\u001b[1;32m     60\u001b[0m                                      \u001b[0;34m'together with shapes '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                      str(shape1) + ' ' + str(shape2))\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (60, 80, 512) (60, 80, 256)"
     ]
    }
   ],
   "source": [
    "# Color branch\n",
    "input_color = Input(shape=(480,640,3), name=\"Color_Input\")\n",
    "x = Model(inputs=input_color, outputs=input_color)\n",
    "\n",
    "# Infrared branch\n",
    "input_ir = Input(shape=(480,640,1), name=\"Infrared_Input\")\n",
    "y = Model(inputs=input_ir, outputs=input_ir)\n",
    "\n",
    "# combine both branches\n",
    "combined = concatenate([x.output, y.output], name=\"Concatenate\")\n",
    "\n",
    "# first skip connection start\n",
    "skip_one = combined\n",
    "\n",
    "# VGG16 style encoder (configuration D)\n",
    "z = Conv2D(64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-64_1\")(combined)\n",
    "z = Conv2D(64, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-64\")(z)\n",
    "\n",
    "# second skip connection start\n",
    "skip_two = z\n",
    "\n",
    "z = Conv2D(128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-128_1\")(z)\n",
    "z = Conv2D(128, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-128\")(z)\n",
    "\n",
    "# third skip connection start\n",
    "skip_three = z\n",
    "\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_1\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_2\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-256_3\")(z)\n",
    "\n",
    "# fourth skip connection start\n",
    "skip_four = z\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_1\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_2\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-512_3\")(z)\n",
    "\n",
    "# fifth skip connection start\n",
    "skip_five = z\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_4\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_5\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Conv3-512_6\")(z)\n",
    "\n",
    "# sixth skip connection start\n",
    "skip_six = z\n",
    "\n",
    "# end of encoder part\n",
    "# start of decoder part\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_7\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_8\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_1\")(z)\n",
    "\n",
    "# fifth skip connection end\n",
    "z = Add()([z, skip_five])\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_9\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_10\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_2\")(z)\n",
    "\n",
    "# fourth skip connection end\n",
    "z = Add()([z, skip_four])\n",
    "\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_11\")(z)\n",
    "z = Conv2D(512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-512_12\")(z)\n",
    "z = Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-512_3\")(z)\n",
    "\n",
    "# third skip connection end\n",
    "z = Add()([z, skip_three])\n",
    "\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_4\")(z)\n",
    "z = Conv2D(256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-256_5\")(z)\n",
    "z = Conv2DTranspose(256, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-256\")(z)\n",
    "\n",
    "# second skip connection end\n",
    "z = Add()([z, skip_two])\n",
    "\n",
    "z = Conv2D(128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-128_2\")(z)\n",
    "z = Conv2DTranspose(128, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"DeConv3-128\")(z)\n",
    "\n",
    "# first skip connection end\n",
    "z = Add()([z, skip_one])\n",
    "\n",
    "z = Conv2D(64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"Conv3-64_2\")(z)\n",
    "\n",
    "# end of decoder part\n",
    "# output layer\n",
    "z = Conv2D(1, kernel_size=(3,3), padding=\"same\", name=\"Conv3-1\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\",\n",
    "    metrics=['mae', 'mse'])\n",
    "\n",
    "\n",
    "\n",
    "# TODO: MaxPool and UpPool replaced with __extra__ conv layer? or simply add strides to last conv layer?\n",
    "# TODO: add BatchNormalization layers\n",
    "# TODO: add skip connections: https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33\n",
    "# TODO: rescale input images to range 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=os.path.join('Images','model.png'), show_shapes=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "           generator=training_generator,\n",
    "           validation_data=validation_generator,\n",
    "           #use_multiprocessing=True,\n",
    "           #workers=6,\n",
    "           epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.json', 'w') as f:\n",
    "    json.dump(hist.history, f)\n",
    "    \n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
