{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Prediction from RGB and Infrared Input\n",
    "\n",
    "This model predicts a depth image given a rgb and an infrared input image of the same resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import Sequence # for data generator class\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Dropout, concatenate, Conv2DTranspose\n",
    "from keras.layers import Add # for skip connections\n",
    "from keras.utils import plot_model\n",
    "import json # for saving training history\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data situation\n",
    "Training data (as well as test and validation data) will lie in directories with the following structure:\n",
    "\n",
    "<pre>\n",
    "data\n",
    "|-- train\n",
    "    |-- Color\n",
    "        |-- 1.jpg\n",
    "        |-- 2.jpg\n",
    "        ...\n",
    "        |-- n.jpg\n",
    "    |-- Infrared\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "    |-- Depth\n",
    "        |-- 1.png\n",
    "        |-- 2.png\n",
    "        ...\n",
    "        |-- n.png\n",
    "|-- test\n",
    "    |-- Color\n",
    "    |-- Infrared\n",
    "    |-- Depth\n",
    "|-- validation\n",
    "    |-- Color\n",
    "    |-- Infrared\n",
    "    |-- Depth\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Generator\n",
    "Because there are many training and test images, it is reasonable to utilize a data loader, which reads training data batch wise. Because the default keras data loader (`ImageDataGenerator`) does not work with two input parameters, we need to write our own. For this, the tutorial from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly is utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Assumes that examples in the provided folder are named from 1 to n, with n being the number of images'\n",
    "    def __init__(self, path_to_data_set='data/train', batch_size=32, image_size=(480,640), shuffle=True, scale_images=False):\n",
    "        self.path_to_data = path_to_data_set\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.scale_images = scale_images\n",
    "        self.training_size = self.__get_training_data_size(self.path_to_data)\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __get_training_data_size(self, path_to_data):\n",
    "        'gets the number of samples'\n",
    "        path_color = os.path.join(path_to_data,'Color')\n",
    "        if os.path.isdir(path_color):\n",
    "            size = len([color for color in os.listdir(path_color) if os.path.isfile(os.path.join(path_color, color))])\n",
    "            return size\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Number of batches per epoche'\n",
    "        return int(np.floor(self.training_size / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Update indices (and their ordering) after each epoch'\n",
    "        # image names start with 1, np.arange(n,m) returns values from n to (m-1)\n",
    "        self.indices = np.arange(1, self.training_size+1)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __data_generation(self, list_images):\n",
    "        'Generates data of size batch_size' # X = (batch_size, 480, 640, 1)\n",
    "        if self.scale_images == False:\n",
    "            X1 = np.empty((self.batch_size, *self.image_size, 3), dtype=np.uint8) # color images\n",
    "            X2 = np.empty((self.batch_size, *self.image_size), dtype=np.uint16) # ir image\n",
    "        else:\n",
    "            X1 = np.empty((self.batch_size, *self.image_size, 3), dtype=np.float32) # color images\n",
    "            X2 = np.empty((self.batch_size, *self.image_size), dtype=np.float32) # ir image\n",
    "        y = np.empty((self.batch_size, *self.image_size), dtype=np.uint16)  # depth image\n",
    "        \n",
    "        # Generate data\n",
    "        for idx, name in enumerate(list_images):\n",
    "            # load images in arrays\n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Color', str(name)+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            if self.scale_images == False:\n",
    "                X1[idx,] = img.astype(np.uint8)\n",
    "            else:\n",
    "                X1[idx,] = (img/255.).astype(np.float32)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Infrared', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            if self.scale_images == False:\n",
    "                X2[idx,] = img.astype(np.uint16)\n",
    "            else:\n",
    "                X2[idx,] = (img/65535.).astype(np.float32)\n",
    "            \n",
    "            img = cv2.imread(os.path.join(self.path_to_data, 'Depth', str(name)+\".png\"), cv2.IMREAD_ANYDEPTH)\n",
    "            y[idx,] = img.astype(np.uint16)\n",
    "        \n",
    "        return X1, X2.reshape(-1, 480, 640, 1), y.reshape(-1, 480, 640, 1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data, X1 contains 8-bit RGB images, X2 16-bit infrared images and y corresponding 16-bit depth images'\n",
    "        # Generate indices of data\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Generate data\n",
    "        X1, X2, y = self.__data_generation(indices)\n",
    "        \n",
    "        return [X1, X2], y\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(\n",
    "    path_to_data_set=os.path.join('data', 'train'),\n",
    "    batch_size=4,\n",
    "    image_size=(480,640),\n",
    "    shuffle=True,\n",
    "    scale_images=True\n",
    "    )\n",
    "\n",
    "validation_generator = DataGenerator(\n",
    "    path_to_data_set=os.path.join('data', 'validation'),\n",
    "    batch_size=4,\n",
    "    image_size=(480,640),\n",
    "    shuffle=True,\n",
    "    scale_images=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Class Definition\n",
    "To make the model more friendly to read (and to prevent the repetition of layer code), this part defines functions to create multiple layers at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG:\n",
    "    'Class that contains building blocks for a residual VGG-like autoencoder network'\n",
    "    def __init__(self):\n",
    "        self.layer_counting = {}\n",
    "        \n",
    "    def Block(self, number_of_layers, units, kernel_size, padding, activation):\n",
    "        'A block of <number_of_layers> convolutions with batch normalization added AFTER the non-linearity'\n",
    "        def Input(z):\n",
    "            for i in range(1,number_of_layers+1):\n",
    "                name = 'Conv' + str(kernel_size[0]) + '-' + str(units)\n",
    "                # make sure we have unique layer names\n",
    "                if name in self.layer_counting:\n",
    "                    self.layer_counting[name] += 1\n",
    "                else:\n",
    "                    self.layer_counting[name] = 1\n",
    "                name += '_' + str(self.layer_counting[name])\n",
    "                name_bn = name + '_BN'\n",
    "                z = Conv2D(filters=units, kernel_size=kernel_size, padding=padding, activation=activation, name=name)(z)\n",
    "                z = BatchNormalization(name=name_bn)(z)\n",
    "            return z\n",
    "        return Input\n",
    "    \n",
    "    def Residual_Downsampling_Block(self, units, kernel_size, padding, activation):\n",
    "        'A block with a strided convolution for downsampling an the start of a skip connection'\n",
    "        def Input(z):\n",
    "            skip = z\n",
    "            name = 'DownConv' + str(kernel_size[0]) + '-' + str(units)\n",
    "            # make sure we have unique layer names\n",
    "            if name in self.layer_counting:\n",
    "                self.layer_counting[name] += 1\n",
    "            else:\n",
    "                self.layer_counting[name] = 1\n",
    "            name += '_' + str(self.layer_counting[name])\n",
    "            name_bn = name + '_BN'\n",
    "            z = Conv2D(filters=units, kernel_size=kernel_size, strides=(2,2), padding=padding, activation=activation, name=name)(z)\n",
    "            z = BatchNormalization(name=name_bn)(z)\n",
    "            return z, skip\n",
    "        return Input\n",
    "    \n",
    "    def Residual_Upsampling_Block(self, units, kernel_size, padding, activation):\n",
    "        'A block with a transposed convolution (also called deconvolution) and the incorporation of a provided skip connection'\n",
    "        def Input(z, skip):\n",
    "            name = 'UpConv' + str(kernel_size[0]) + '-' + str(units)\n",
    "            # make sure we have unique layer names\n",
    "            if name in self.layer_counting:\n",
    "                self.layer_counting[name] += 1\n",
    "            else:\n",
    "                self.layer_counting[name] = 1\n",
    "            name += '_' + str(self.layer_counting[name])\n",
    "            name_add = name + '_skip'\n",
    "            name_bn = name + '_BN'\n",
    "            z = Conv2DTranspose(filters=units, kernel_size=kernel_size, strides=(2,2), padding=\"same\", name=name)(z)\n",
    "            z = Add(name=name_add)([z, skip])\n",
    "            z = Activation(activation)(z)\n",
    "            z = BatchNormalization(name=name_bn)(z)\n",
    "            return z\n",
    "        return Input\n",
    "    \n",
    "    def Residual_Block(self, number_of_layers, units, kernel_size, padding, activation):\n",
    "        'A block of <number_of_layers> covolutions with provided skip connection incorporated after the last convolutional layer'\n",
    "        def Input(z, skip):\n",
    "            for i in range(1, number_of_layers+1):\n",
    "                name = 'Conv2D' + str(kernel_size[0]) + '-' + str(units)\n",
    "                # make sure we have unique layer names\n",
    "                if name in self.layer_counting:\n",
    "                    self.layer_counting[name] += 1\n",
    "                else:\n",
    "                    self.layer_counting[name] = 1\n",
    "                name += '_' + str(self.layer_counting[name])\n",
    "                name_add = name + '_skip'\n",
    "                name_bn = name + '_BN'\n",
    "                z = Conv2D(filters=units, kernel_size=kernel_size, padding=padding)(z)\n",
    "                if i == number_of_layers:\n",
    "                    z = Add(name=name_add)([z, skip])\n",
    "                z = Activation(activation)(z)\n",
    "                z = BatchNormalization(name=name_bn)(z)\n",
    "            return z\n",
    "        return Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function\n",
    "Here a custom loss function is implemented. It is based on the mean absolut error but uses a binary map to eliminate the influence of artifacts in the ground truth. Beware: This loss function is written for 16bit input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Binary_Mean_Absolut_Error(y_true, y_pred):\n",
	"    # code of fabian follows\n",
	"    # shape of y_true and y_pred is (batch_size, 480, 640, 1); rank = 4\n",
    "    # edit by fabian\n",
    "    y_zero = tf.zeros(tf.shape(y_true))  # rank = 4\n",
    "    A_i = tf.math.greater(y_true, y_zero) # rank = 4\n",
    "    A_i_sum = tf.reduce_sum(A_i, axis = (1, rank(A_i))) # sum for every batch; rank = 1, but still a 1D vector  \n",
    "    \n",
    "    A_comb = tf.math.multiply(A_i, tf.math.abs(tf.math.subtract(y_true, y_pred))) # A * |y_true - y_pred|; rank = 4\n",
    "    A_batch = tf.reduce_sum(A_comb, axis = (1, rank(A_comb))) # should be rank = 1\n",
    "    \n",
    "    A_divide = tf.math.divide(A_batch, A_i_sum) # still rank = 1\n",
    "    \n",
    "    output = tf.reduce_sum(A_divide) # rank = 0 --> a scalar = Loss for the whole batch\n",
    "    \n",
    "    return output\n",
	"    # code of julien follows\n",
    "    # shape of y_true and y_pred is (batch_size, 480, 640, 1)\n",
    "    #zeros = K.zeros(shape=y_true.shape, dtype=K.dtypes.uint16)\n",
    "    \n",
    "    \n",
    "    binary_map_bool = K.greater(y_true, 0) # if this does not work, use zeros from top\n",
    "    binary_map = K.cast(binary_map_bool, 'uint16')\n",
    "    \n",
    "    #sum_binary = K.reduce_sum(binary_map)\n",
    "    sum_binary = tf.reduce_sum(binary_map)\n",
    "    \n",
    "    x = K.cast(K.abs(y_true - y_pred), 'uint16')\n",
    "    y = binary_map * x\n",
    "    z = y / sum_binary\n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual model\n",
    "This section defines the network architecture of the neural network. It consists of different parts:\n",
    "- input layers\n",
    "- fusion layer\n",
    "- VGG16-like encoder network (configuration D) (see https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- mirrored decoder network\n",
    "- output\n",
    "\n",
    "The encoder and decoder sections are connected through skip connections between layers of equal spatial size (as described in https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG()\n",
    "# Color branch\n",
    "input_color = Input(shape=(480,640,3), name=\"Color_Input\")\n",
    "x = Model(inputs=input_color, outputs=input_color)\n",
    "\n",
    "# Infrared branch\n",
    "input_ir = Input(shape=(480,640,1), name=\"Infrared_Input\")\n",
    "y = Model(inputs=input_ir, outputs=input_ir)\n",
    "\n",
    "# combine both branches\n",
    "combined = concatenate([x.output, y.output], name=\"Concatenate\")\n",
    "\n",
    "# zeroth skip connection start --> to transfer original input images to the end of the network\n",
    "skip_zero = combined\n",
    "\n",
    "# VGG16 style encoder (configuration D)\n",
    "\n",
    "z = vgg.Block(number_of_layers=2, units=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(combined)\n",
    "# max pooling replaced with strided convolution + first skip connection start\n",
    "z, skip_one = vgg.Residual_Downsampling_Block(units=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "z = vgg.Block(number_of_layers=2, units=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "# max pooling replaced with strided convolution + second skip connection start\n",
    "z, skip_two = vgg.Residual_Downsampling_Block(units=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "z = vgg.Block(number_of_layers=3, units=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "# max pooling replaced with strided convolution + third skip connection start\n",
    "z, skip_three = vgg.Residual_Downsampling_Block(units=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "# max pooling replaced with strided convolution + fourth skip connection start\n",
    "z, skip_four = vgg.Residual_Downsampling_Block(units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "# max pooling replaced with strided convolution + fifth skip connection start\n",
    "z, skip_five = vgg.Residual_Downsampling_Block(units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "# end of encoder part\n",
    "\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "# start of decoder part (= mirrored encoder part)\n",
    "\n",
    "# upsampling with deconvolution + fifth skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_five)\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "# upsampling with deconvolution + fourth skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_four)\n",
    "z = vgg.Block(number_of_layers=3, units=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "# upsampling with deconvolution + third skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_three)\n",
    "z = vgg.Block(number_of_layers=3, units=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "# upsampling with deconvolution + second skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_two)\n",
    "z = vgg.Block(number_of_layers=2, units=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "\n",
    "# upsampling with deconvolution + first skip connection target\n",
    "z = vgg.Residual_Upsampling_Block(units=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_one)\n",
    "z = vgg.Block(number_of_layers=2, units=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z)\n",
    "\n",
    "# end of decoder part\n",
    "\n",
    "# TODO does incorporating skip_zero in this way makes sense?\n",
    "z = vgg.Residual_Block(number_of_layers=1, units=4, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(z, skip_zero)\n",
    "\n",
    "# output layer\n",
    "z = Conv2D(1, kernel_size=(3,3), padding=\"same\", name=\"Conv_Output\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    #loss=\"mae\",\n",
    "    loss=Binary_Mean_Absolut_Error,\n",
    "    metrics=['mae', 'mse'])\n",
    "\n",
    "# TODO implement own loss function: https://towardsdatascience.com/advanced-keras-constructing-complex-custom-losses-and-metrics-c07ca130a618\n",
    "# and https://medium.com/@yanfengliux/on-writing-custom-loss-functions-in-keras-e04290dd7a96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, to_file=os.path.join('Images','model.png'), show_shapes=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b163b443e1e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m            \u001b[1;31m#use_multiprocessing=True,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m            \u001b[1;31m#workers=6,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m            epochs=10)\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[0;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m                         loss=self.total_loss)\n\u001b[0m\u001b[0;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[0;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             raise ValueError('An operation has `None` for gradient. '\n\u001b[0m\u001b[0;32m     92\u001b[0m                              \u001b[1;34m'Please make sure that all of your ops have a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                              \u001b[1;34m'gradient defined (i.e. are differentiable). '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval."
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "           generator=training_generator,\n",
    "           validation_data=validation_generator,\n",
    "           #use_multiprocessing=True,\n",
    "           #workers=6,\n",
    "           epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.json', 'w') as f:\n",
    "    json.dump(hist.history, f)\n",
    "    \n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
