{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Dropout, concatenate, Conv2DTranspose\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    Scale = 0.0\n",
    "    with open(os.path.join('Beleg', 'Scale.txt'), 'r') as f:\n",
    "        Scale = float(f.readline())\n",
    "        \n",
    "    path_train_color = os.path.join('Beleg', 'train', 'Color')\n",
    "    path_train_ir = os.path.join('Beleg', 'train', 'IR')\n",
    "    path_train_depth = os.path.join('Beleg', 'train', 'Depth')\n",
    "    \n",
    "    path_test_color = os.path.join('Beleg', 'test', 'Color')\n",
    "    path_test_ir = os.path.join('Beleg', 'test', 'IR')\n",
    "    path_test_depth = os.path.join('Beleg', 'test', 'Depth')\n",
    "    \n",
    "    files_train_color = os.listdir(path_train_color)\n",
    "    files_test_color = os.listdir(path_test_color)\n",
    "    \n",
    "    train_color = [file for file in files_train_color if file[-4:] == '.jpg']\n",
    "    test_color = [file for file in files_test_color if file[-4:] == '.jpg']\n",
    "    \n",
    "    X_train_color = []\n",
    "    X_train_ir = []\n",
    "    y_train = []\n",
    "    X_test_color = []\n",
    "    X_test_ir = []\n",
    "    y_test = []\n",
    "    invalid_images = 0\n",
    "    \n",
    "    for file in train_color:\n",
    "        color = cv2.imread(os.path.join(path_train_color, file))\n",
    "        ir = cv2.imread(os.path.join(path_train_ir, file), cv2.IMREAD_GRAYSCALE)\n",
    "        depth = cv2.imread(os.path.join(path_train_depth, file[:-4]+'.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        if color is None or ir is None or depth is None:\n",
    "            invalid_images += 1\n",
    "            continue\n",
    "        color = cv2.resize(color, (256,256), interpolation=cv2.INTER_AREA)\n",
    "        ir = cv2.resize(ir, (256,256), interpolation=cv2.INTER_AREA)\n",
    "        depth = cv2.resize(depth, (256,256), interpolation=cv2.INTER_AREA)\n",
    "        #depth = np.asarray(Scale*depth, dtype=np.float32)\n",
    "        X_train_color.append(color)\n",
    "        X_train_ir.append(ir)\n",
    "        y_train.append(depth)\n",
    "        \n",
    "    for file in test_color:\n",
    "        color = cv2.imread(os.path.join(path_test_color, file))\n",
    "        ir = cv2.imread(os.path.join(path_test_ir, file), cv2.IMREAD_GRAYSCALE)\n",
    "        depth = cv2.imread(os.path.join(path_test_depth, file[:-4]+'.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        if color is None or ir is None or depth is None:\n",
    "            invalid_images += 1\n",
    "            continue\n",
    "        color = cv2.resize(color, (256,256), cv2.INTER_AREA)\n",
    "        ir = cv2.resize(ir, (256,256), cv2.INTER_AREA)\n",
    "        depth = cv2.resize(depth, (256,256), cv2.INTER_AREA)\n",
    "        #depth = np.asarray(Scale*depth, dtype=np.float32)\n",
    "        X_test_color.append(color)\n",
    "        X_test_ir.append(ir)\n",
    "        y_test.append(depth)\n",
    "        \n",
    "    return np.asarray(X_train_color), np.asarray(X_train_ir), np.asarray(y_train), np.asarray(X_test_color), np.asarray(X_test_ir), np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_color, X_train_ir, y_train, X_test_color, X_test_ir, y_test = load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_color = Input(shape=(256,256,3), name=\"Color_Input\")\n",
    "input_ir = Input(shape=(256,256,1), name=\"IR_Input\")\n",
    "\n",
    "# Color branch\n",
    "x = Conv2D(256, (5,5), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Color_Conv2D_1\")(input_color)\n",
    "x = Conv2D(128, (3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Color_Conv2D_2\")(x)\n",
    "x = Model(inputs=input_color, outputs=x)\n",
    "\n",
    "# IR branch\n",
    "y = Conv2D(256, (5,5), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"IR_Conv2D_1\")(input_ir)\n",
    "y = Conv2D(128, (3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"IR_Conv2D_2\")(y)\n",
    "y = Model(inputs=input_ir, outputs=y)\n",
    "\n",
    "# combine both branches\n",
    "combined = concatenate([x.output, y.output], name=\"Concat\")\n",
    "\n",
    "z = Conv2D(64, (3,3), strides=(1,1), padding=\"same\", activation=\"relu\", name=\"Comb_Conv2D_1\")(combined)\n",
    "z = Conv2DTranspose(128, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Comb_DeConv2D_1\")(z)\n",
    "z = Conv2DTranspose(256, kernel_size=(5,5), strides=(2,2), padding=\"same\", activation=\"relu\", name=\"Comb_DeConv2D_2\")(z)\n",
    "z = Conv2D(256, kernel_size=(5,5), strides=(1,1), padding=\"same\", activation=\"relu\", name=\"Comb_Conv2D_2\")(z)\n",
    "z = Conv2D(1, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\", name=\"Comb_Conv2D_3\")(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\",\n",
    "    metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Color_Input (InputLayer)        (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "IR_Input (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Color_Conv2D_1 (Conv2D)         (None, 128, 128, 256 19456       Color_Input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "IR_Conv2D_1 (Conv2D)            (None, 128, 128, 256 6656        IR_Input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Color_Conv2D_2 (Conv2D)         (None, 64, 64, 128)  295040      Color_Conv2D_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "IR_Conv2D_2 (Conv2D)            (None, 64, 64, 128)  295040      IR_Conv2D_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Concat (Concatenate)            (None, 64, 64, 256)  0           Color_Conv2D_2[0][0]             \n",
      "                                                                 IR_Conv2D_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Comb_Conv2D_1 (Conv2D)          (None, 64, 64, 64)   147520      Concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Comb_DeConv2D_1 (Conv2DTranspos (None, 128, 128, 128 73856       Comb_Conv2D_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Comb_DeConv2D_2 (Conv2DTranspos (None, 256, 256, 256 819456      Comb_DeConv2D_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Comb_Conv2D_2 (Conv2D)          (None, 256, 256, 256 1638656     Comb_DeConv2D_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Comb_Conv2D_3 (Conv2D)          (None, 256, 256, 1)  2305        Comb_Conv2D_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,297,985\n",
      "Trainable params: 3,297,985\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159 samples, validate on 40 samples\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 8s 52ms/step - loss: 20.2807 - mean_absolute_error: 20.2807 - mean_squared_error: 1325.2916 - val_loss: 7.4418 - val_mean_absolute_error: 7.4418 - val_mean_squared_error: 80.8077\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 5.0790 - mean_absolute_error: 5.0790 - mean_squared_error: 43.7943 - val_loss: 3.8825 - val_mean_absolute_error: 3.8825 - val_mean_squared_error: 25.8778\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 4.0309 - mean_absolute_error: 4.0309 - mean_squared_error: 30.6587 - val_loss: 3.5204 - val_mean_absolute_error: 3.5204 - val_mean_squared_error: 21.7867\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 3.9543 - mean_absolute_error: 3.9543 - mean_squared_error: 29.9228 - val_loss: 3.4697 - val_mean_absolute_error: 3.4697 - val_mean_squared_error: 20.8659\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 4.1968 - mean_absolute_error: 4.1968 - mean_squared_error: 32.7244 - val_loss: 3.6565 - val_mean_absolute_error: 3.6565 - val_mean_squared_error: 22.2203\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 4.0127 - mean_absolute_error: 4.0127 - mean_squared_error: 30.2113 - val_loss: 3.5938 - val_mean_absolute_error: 3.5938 - val_mean_squared_error: 23.8557\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 4.0175 - mean_absolute_error: 4.0175 - mean_squared_error: 30.5180 - val_loss: 3.2202 - val_mean_absolute_error: 3.2202 - val_mean_squared_error: 19.8944\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 3.6369 - mean_absolute_error: 3.6369 - mean_squared_error: 26.6972 - val_loss: 3.3339 - val_mean_absolute_error: 3.3339 - val_mean_squared_error: 21.9732\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 3.5821 - mean_absolute_error: 3.5821 - mean_squared_error: 26.1635 - val_loss: 2.8702 - val_mean_absolute_error: 2.8702 - val_mean_squared_error: 17.6504\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 7s 47ms/step - loss: 3.5781 - mean_absolute_error: 3.5781 - mean_squared_error: 26.7060 - val_loss: 3.6499 - val_mean_absolute_error: 3.6499 - val_mean_squared_error: 21.2501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2000b49987f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X_train_color, X_train_ir.reshape(-1,256,256,1)],\n",
    "    y_train.reshape(-1, 256,256,1),\n",
    "    epochs=10,\n",
    "    batch_size = 10,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 4  3 11 ...  0  0  0]\n",
      " [ 2  8 11 ...  0  0  0]\n",
      " [ 0 11 11 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = model.predict([X_test_color[0].reshape(1,256,256,3), X_test_ir[0].reshape(-1, 256,256,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(d.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1790194e-02, 1.1515117e+00, 2.9213803e+00, ..., 1.9578234e+01,\n",
       "        1.5119235e+01, 8.5555696e+00],\n",
       "       [0.0000000e+00, 2.3562118e-01, 1.1595874e+00, ..., 1.8867699e+01,\n",
       "        1.6861765e+01, 6.0285015e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 5.6677002e-01, ..., 1.8725613e+01,\n",
       "        1.5308620e+01, 7.8550739e+00],\n",
       "       ...,\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 8.2696228e+00,\n",
       "        6.8757601e+00, 2.9774649e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 7.5296264e+00,\n",
       "        5.5849175e+00, 2.7945225e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 6.7869473e+00,\n",
       "        4.9226336e+00, 2.2981105e+00]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.reshape(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
