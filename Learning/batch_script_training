#!/bin/bash

#Submit this script with: sbatch thefilename

#SBATCH --time=50:00:00   # walltime
#SBATCH --nodes=1   # number of nodes
#SBATCH --gres=gpu:1
#SBATCH --ntasks=1      # limit to one node
#SBATCH --cpus-per-task=1  # number of processor cores (i.e. threads)
#SBATCH --partition=ml
#SBATCH --mem-per-cpu=8000M   # memory per CPU core
#SBATCH -J "Training_1"   # job name
#SBATCH --mail-user=julien.fischer@mailbox.tu-dresden.de   # email address
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH -A p_da_rgb


# Set the max number of threads to use for programs using OpenMP. Should be <= ppn. Does nothing if the program doesn't use OpenMP.
export OMP_NUM_THREADS=$SLURM_CPUS_ON_NODE

# The optimizer to utilize
OPT=adam

# The number of epochs
EPOCHS=100

SAVE_FOLDER="results_training/""$OPT"_"$EPOCHS"

OUTFILE=$SAVE_FOLDER"/training_output.txt"

mkdir -p $SAVE_FOLDER
module load modenv/ml
module load TensorFlow/1.14.0-PythonAnaconda-3.6
python /scratch/ws/fahe458b-p_da_rgb-depth_estimation_CNN/Model_VGG_Style.py -t /scratch/ws/fahe458b-p_da_rgb-depth_estimation_CNN/data -x /scratch/ws/fahe458b-p_da_rgb-depth_estimation_CNN/"$SAVE_FOLDER" -b 4 -e $EPOCHS -s True -i True -p 5 -o "$OPT" -d 10 -f 0.5 -c True -m 0.6 > "$OUTFILE"

exit 0
